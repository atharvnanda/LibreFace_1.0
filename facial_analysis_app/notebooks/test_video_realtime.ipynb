{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66fbed57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tempfile\n",
    "from libreface.AU_Recognition.solver_inference_combine import solver_inference_image_task_combine\n",
    "import torch\n",
    "import random\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84937eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "weights_dir = \"./weights_libreface\"\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "os.makedirs(temp_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbfbe6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigObject:\n",
    "    def __init__(self, config_dict):\n",
    "        for key, value in config_dict.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "class CustomSolver(solver_inference_image_task_combine):\n",
    "    def run_pil(self, image_pil, task=\"au_recognition\"):  # ADD THIS\n",
    "        # Define image transform (same as original image_test class)\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(self.img_size),\n",
    "            transforms.CenterCrop(self.crop_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "        transformed_image = transform(image_pil)\n",
    "\n",
    "        if task == \"au_recognition\":\n",
    "            pred_labels = self.image_inference_au_recognition(transformed_image)\n",
    "            pred_labels = pred_labels.squeeze().tolist()\n",
    "            return dict(zip(self.au_recognition_aus, pred_labels))\n",
    "        elif task == \"au_detection\":\n",
    "            pred_labels = self.image_inference_au_detection(transformed_image)\n",
    "            pred_labels = pred_labels.squeeze().tolist()\n",
    "            return dict(zip(self.au_detection_aus, pred_labels))\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Unsupported task: {task}\")\n",
    "        \n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "def format_output(out_dict, task = \"au_recognition\"):\n",
    "    new_dict = {}\n",
    "    for k, v in out_dict.items():\n",
    "        if task == \"au_recognition\":\n",
    "            new_dict[f\"au_{k}_intensity\"] = round(v, 3)\n",
    "        elif task == \"au_detection\":\n",
    "            new_dict[f\"au_{k}\"] = v\n",
    "        else:\n",
    "            raise NotImplementedError(f\"format_output() not defined for the task - {task}\")\n",
    "    return new_dict\n",
    "\n",
    "def get_au_intensities_and_detect_aus_from_frame(frame, device=\"cpu\", weights_download_dir=\"./weights_libreface\"):\n",
    "    opts = ConfigObject({\n",
    "        'seed': 0,\n",
    "        'ckpt_path': f'{weights_download_dir}/AU_Recognition/weights/combined_resnet.pt',\n",
    "        'weights_download_id': \"1CbnBr8OBt8Wb73sL1ENcrtrWAFWSSRv0\",\n",
    "        'image_inference': False,\n",
    "        'au_recognition_data_root': '',\n",
    "        'au_recognition_data': 'DISFA',\n",
    "        'au_detection_data_root': '',\n",
    "        'au_detection_data': 'BP4D',\n",
    "        'fer_train_csv': 'training_filtered.csv',\n",
    "        'fer_test_csv': 'validation_filtered.csv',\n",
    "        'fer_data_root': '',\n",
    "        'fer_data': 'AffectNet',\n",
    "        'fold': 'all',\n",
    "        'image_size': 256,\n",
    "        'crop_size': 224,\n",
    "        'au_recognition_num_labels': 12,\n",
    "        'au_detection_num_labels': 12,\n",
    "        'fer_num_labels': 8,\n",
    "        'sigma': 10.0,\n",
    "        'jitter': False,\n",
    "        'copy_classifier': False,\n",
    "        'model_name': 'resnet',\n",
    "        'dropout': 0.1,\n",
    "        'ffhq_pretrain': '',\n",
    "        'hidden_dim': 128,\n",
    "        'fm_distillation': False,\n",
    "        'num_epochs': 30,\n",
    "        'interval': 500,\n",
    "        'threshold': 0,\n",
    "        'batch_size': 256,\n",
    "        'learning_rate': 3e-5,\n",
    "        'weight_decay': 1e-4,\n",
    "        'clip': 1.0,\n",
    "        'when': 10,\n",
    "        'patience': 5,\n",
    "        'device': device\n",
    "    })\n",
    "\n",
    "    set_seed(opts.seed)\n",
    "    solver = CustomSolver(opts).to(device)\n",
    "\n",
    "    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    pil_image = Image.fromarray(image_rgb).resize((256, 256), Image.Resampling.LANCZOS)\n",
    "\n",
    "    detected_aus = solver.run(pil_image, task=\"au_detection\")\n",
    "    au_intensities = solver.run(pil_image, task=\"au_recognition\")\n",
    "\n",
    "    return format_output(detected_aus, task=\"au_detection\"), format_output(au_intensities, task=\"au_recognition\")\n",
    "\n",
    "def draw_aus_on_frame(frame, aus: dict):\n",
    "    y0, dy = 30, 30\n",
    "    for i, (au, intensity) in enumerate(aus.items()):\n",
    "        y = y0 + i * dy\n",
    "        label = f\"{au}: {intensity:.2f}\"\n",
    "        cv2.putText(frame, label, (10, y), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dadc333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting webcam AU detection...\n",
      "Exiting...\n",
      "Webcam AU detection stopped.\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting webcam AU detection...\")\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "if not cam.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "    exit()\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "opts = ConfigObject({\n",
    "    'seed': 0,\n",
    "    'ckpt_path': f'{weights_dir}/AU_Recognition/weights/combined_resnet.pt',\n",
    "    'weights_download_id': \"1CbnBr8OBt8Wb73sL1ENcrtrWAFWSSRv0\",\n",
    "    'image_inference': False,\n",
    "    'au_recognition_data_root': '',\n",
    "    'au_recognition_data': 'DISFA',\n",
    "    'au_detection_data_root': '',\n",
    "    'au_detection_data': 'BP4D',\n",
    "    'fer_train_csv': 'training_filtered.csv',\n",
    "    'fer_test_csv': 'validation_filtered.csv',\n",
    "    'fer_data_root': '',\n",
    "    'fer_data': 'AffectNet',\n",
    "    'fold': 'all',\n",
    "    'image_size': 256,\n",
    "    'crop_size': 224,\n",
    "    'au_recognition_num_labels': 12,\n",
    "    'au_detection_num_labels': 12,\n",
    "    'fer_num_labels': 8,\n",
    "    'sigma': 10.0,\n",
    "    'jitter': False,\n",
    "    'copy_classifier': False,\n",
    "    'model_name': 'resnet',\n",
    "    'dropout': 0.1,\n",
    "    'ffhq_pretrain': '',\n",
    "    'hidden_dim': 128,\n",
    "    'fm_distillation': False,\n",
    "    'num_epochs': 30,\n",
    "    'interval': 500,\n",
    "    'threshold': 0,\n",
    "    'batch_size': 256,\n",
    "    'learning_rate': 3e-5,\n",
    "    'weight_decay': 1e-4,\n",
    "    'clip': 1.0,\n",
    "    'when': 10,\n",
    "    'patience': 5,\n",
    "    'device': device\n",
    "})\n",
    "\n",
    "set_seed(opts.seed)\n",
    "solver = CustomSolver(opts).to(device)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        success,frame = cam.read()\n",
    "        if not success:\n",
    "            print(\"Error: Could not read frame from webcam.\")\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "        # if frame_count % 5 != 0: \n",
    "        #     continue\n",
    "\n",
    "        try:\n",
    "            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) \n",
    "            pil_image = Image.fromarray(image_rgb)            \n",
    "\n",
    "    \n",
    "            detected_aus = solver.run_pil(pil_image, task=\"au_detection\")      \n",
    "            au_intensities = solver.run_pil(pil_image, task=\"au_recognition\")\n",
    "\n",
    "            annotated_data = {au: float(f\"{au_intensities[au]:.2f}\") for au in au_intensities}\n",
    "            annotated_frame = draw_aus_on_frame(frame.copy(), annotated_data)\n",
    "\n",
    "            cv2.imshow(\"Webcam AU Detection\", annotated_frame)\n",
    "        except Exception as e:\n",
    "            print(f\"Error during AU detection: {e}\")\n",
    "            cv2.imshow(\"Webcam AU Detection\", frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            print(\"Exiting...\")\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Webcam AU detection stopped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b89273f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
