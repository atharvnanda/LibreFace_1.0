{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7b8962",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'libreface.core'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mipywidgets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m widgets, interact\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlibreface\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlibreface\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference_engine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InferenceEngine\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlibreface\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m detection, landmarking, landmarks_postprocessing, action_units\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'libreface.core'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from IPython.display import display, clear_output\n",
    "from ipywidgets import widgets, interact\n",
    "from libreface.core.inference_engine import InferenceEngine\n",
    "from libreface.modules import detection, landmarking, landmarks_postprocessing, action_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501fba5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_libreface_engine():\n",
    "    # Set device (GPU if available, otherwise CPU)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Initialize inference engine\n",
    "    engine = InferenceEngine(device=device)\n",
    "    \n",
    "    # Add required modules for AU detection\n",
    "    engine.add_module(\"face_detector\", detection.RetinaFace())  # Face detection\n",
    "    engine.add_module(\"landmark_detector\", landmarking.Fan2D())  # Facial landmark detection\n",
    "    engine.add_module(\"landmark_postprocessor\", landmarks_postprocessing.FANPostProcessor())  # Refine landmarks\n",
    "    engine.add_module(\"au_detector\", action_units.AU())  # Action unit detection\n",
    "    \n",
    "    return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39525d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_for_au(video_path, output_dir=None, display_in_notebook=True, max_frames=None):\n",
    "    \"\"\"\n",
    "    Process a video to detect action units using LibreFace\n",
    "    \n",
    "    Args:\n",
    "        video_path: Path to the video file\n",
    "        output_dir: Directory to save results (if None, results won't be saved)\n",
    "        display_in_notebook: Whether to display frames in the notebook\n",
    "        max_frames: Maximum number of frames to process (None for all frames)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with frame indices as keys and AU predictions as values\n",
    "    \"\"\"\n",
    "    # Create output directory if specified\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Initialize the video capture\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(f\"Could not open video file: {video_path}\")\n",
    "    \n",
    "    print(f\"Successfully opened video: {video_path}\")\n",
    "    \n",
    "    # Get video properties\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    print(f\"Video properties: {frame_width}x{frame_height}, {fps} FPS, {total_frames} frames total\")\n",
    "    \n",
    "    # Set up LibreFace inference engine\n",
    "    engine = setup_libreface_engine()\n",
    "    \n",
    "    # Initialize video writer if output_dir is specified\n",
    "    out = None\n",
    "    if output_dir:\n",
    "        output_path = os.path.join(output_dir, f\"{Path(video_path).stem}_au_output.mp4\")\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "        print(f\"Output video will be saved to: {output_path}\")\n",
    "    \n",
    "    # Dictionary to store AU results\n",
    "    au_results = {}\n",
    "    \n",
    "    # For notebook display\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.axis('off')\n",
    "    display_handle = display(None, display_id=True)\n",
    "    \n",
    "    frame_idx = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or (max_frames is not None and frame_idx >= max_frames):\n",
    "            break\n",
    "        \n",
    "        # BGR to RGB conversion\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Process the frame with LibreFace\n",
    "        result = engine.process({\"image\": rgb_frame})\n",
    "        \n",
    "        # Extract AU predictions\n",
    "        if \"aus\" in result and result[\"aus\"] is not None and len(result[\"aus\"]) > 0:\n",
    "            au_results[frame_idx] = result[\"aus\"]\n",
    "        \n",
    "        # Visualize results on the frame\n",
    "        vis_frame = frame.copy()\n",
    "        \n",
    "        # Draw face bounding boxes\n",
    "        if \"detections\" in result and result[\"detections\"] is not None:\n",
    "            for det in result[\"detections\"]:\n",
    "                box = det.box.astype(int)\n",
    "                cv2.rectangle(vis_frame, (box[0], box[1]), (box[2], box[3]), (0, 255, 0), 2)\n",
    "        \n",
    "        # Draw landmarks\n",
    "        if \"landmarks\" in result and result[\"landmarks\"] is not None:\n",
    "            for lmks in result[\"landmarks\"]:\n",
    "                for (x, y) in lmks.astype(int):\n",
    "                    cv2.circle(vis_frame, (x, y), 2, (0, 0, 255), -1)\n",
    "        \n",
    "        # Display AU values\n",
    "        if frame_idx in au_results:\n",
    "            aus = au_results[frame_idx]\n",
    "            for i, (face_aus, face_scores) in enumerate(aus):\n",
    "                y_offset = 30\n",
    "                for j, (au, score) in enumerate(zip(face_aus, face_scores)):\n",
    "                    text = f\"AU{au}: {score:.2f}\"\n",
    "                    cv2.putText(vis_frame, text, (10, y_offset + j*20), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
    "        \n",
    "        # Write frame to output video\n",
    "        if out:\n",
    "            out.write(vis_frame)\n",
    "        \n",
    "        # Display the frame in the notebook\n",
    "        if display_in_notebook and frame_idx % 5 == 0:  # Update display every 5 frames for efficiency\n",
    "            rgb_vis_frame = cv2.cvtColor(vis_frame, cv2.COLOR_BGR2RGB)\n",
    "            plt.imshow(rgb_vis_frame)\n",
    "            plt.title(f\"Frame {frame_idx}/{total_frames}\")\n",
    "            display_handle.update(plt.gcf())\n",
    "            plt.clf()\n",
    "            plt.axis('off')\n",
    "        \n",
    "        frame_idx += 1\n",
    "        \n",
    "        # Print progress every 100 frames\n",
    "        if frame_idx % 100 == 0:\n",
    "            print(f\"Processed {frame_idx} frames out of {total_frames if max_frames is None else max_frames}\")\n",
    "    \n",
    "    # Cleanup\n",
    "    cap.release()\n",
    "    if out:\n",
    "        out.release()\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Processed {frame_idx} frames total\")\n",
    "    print(f\"Detected faces with AU in {len(au_results)} frames\")\n",
    "    \n",
    "    return au_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbf2d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_au_results_to_csv(au_results, output_path):\n",
    "    \"\"\"\n",
    "    Save AU results to a CSV file\n",
    "    \n",
    "    Args:\n",
    "        au_results: Dictionary with frame indices as keys and AU predictions as values\n",
    "        output_path: Path to save the CSV file\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for frame_idx, aus in au_results.items():\n",
    "        for face_idx, (face_aus, face_scores) in enumerate(aus):\n",
    "            for au, score in zip(face_aus, face_scores):\n",
    "                data.append({\n",
    "                    'frame_idx': frame_idx,\n",
    "                    'face_idx': face_idx,\n",
    "                    'au': f'AU{au}',\n",
    "                    'score': score\n",
    "                })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Saved AU results to {output_path}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f96e56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_au_data(au_results):\n",
    "    \"\"\"\n",
    "    Plot AU scores over time for visualization\n",
    "    \"\"\"\n",
    "    # Convert to dataframe\n",
    "    data = []\n",
    "    for frame_idx, aus in au_results.items():\n",
    "        for face_idx, (face_aus, face_scores) in enumerate(aus):\n",
    "            for au, score in zip(face_aus, face_scores):\n",
    "                data.append({\n",
    "                    'frame_idx': frame_idx,\n",
    "                    'face_idx': face_idx,\n",
    "                    'au': f'AU{au}',\n",
    "                    'score': score\n",
    "                })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    if len(df) == 0:\n",
    "        print(\"No AU data to plot\")\n",
    "        return\n",
    "    \n",
    "    # Get unique AUs and faces\n",
    "    unique_aus = sorted(df['au'].unique())\n",
    "    unique_faces = sorted(df['face_idx'].unique())\n",
    "    \n",
    "    # Create one plot per face\n",
    "    for face_idx in unique_faces:\n",
    "        face_data = df[df['face_idx'] == face_idx]\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        \n",
    "        for au in unique_aus:\n",
    "            au_data = face_data[face_data['au'] == au]\n",
    "            if not au_data.empty:\n",
    "                plt.plot(au_data['frame_idx'], au_data['score'], label=au)\n",
    "        \n",
    "        plt.title(f\"Action Unit Scores for Face #{face_idx}\")\n",
    "        plt.xlabel(\"Frame\")\n",
    "        plt.ylabel(\"AU Score\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a01548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to your video file\n",
    "video_path = \"path/to/your/video.mp4\"  # Change this to your video path\n",
    "\n",
    "# Set output directory (optional)\n",
    "output_dir = \"results\"  # Change or set to None if you don't want to save results\n",
    "\n",
    "# Maximum frames to process (optional, set to None to process all frames)\n",
    "max_frames = 300  # Process first 300 frames, set to None for full video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886aa9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the AU detection\n",
    "au_results = process_video_for_au(\n",
    "    video_path=video_path,\n",
    "    output_dir=output_dir,\n",
    "    display_in_notebook=True,\n",
    "    max_frames=max_frames\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f9c49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if output_dir and au_results:\n",
    "    output_csv = os.path.join(output_dir, f\"{Path(video_path).stem}_au_results.csv\")\n",
    "    df = save_au_results_to_csv(au_results, output_csv)\n",
    "    \n",
    "    # Display the first few rows\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0ff0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the AU scores over time\n",
    "if au_results:\n",
    "    plot_au_data(au_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
