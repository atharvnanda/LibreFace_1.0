{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c4765cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from libreface.utils import get_frames_from_video_opencv\n",
    "from libreface.AU_Recognition.inference import get_au_intensities_and_detect_aus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "311d656d",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"D:/ATHARV/W/CDAC/CODE/LIBREFACE_IMPLEMENT/Data/sample_video.avi\"\n",
    "temp_dir = \"./tmp\"\n",
    "device = \"cpu\"\n",
    "output_dir = \"D:/ATHARV/W/CDAC/CODE/LIBREFACE_IMPLEMENT/Notebooks/results\"\n",
    "weights_dir = \"./weights_libreface\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96657b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames...\n",
      "Processed: 0000000000.png\n",
      "Processed: 0000000005.png\n",
      "Processed: 0000000010.png\n",
      "Processed: 0000000015.png\n",
      "Processed: 0000000020.png\n",
      "Processed: 0000000025.png\n",
      "Processed: 0000000030.png\n",
      "Processed: 0000000035.png\n",
      "Processed: 0000000040.png\n",
      "Processed: 0000000045.png\n",
      "Processed: 0000000050.png\n",
      "Processed: 0000000055.png\n",
      "Processed: 0000000060.png\n",
      "Processed: 0000000065.png\n",
      "Processed: 0000000070.png\n",
      "Processed: 0000000075.png\n",
      "Processed: 0000000080.png\n",
      "Processed: 0000000085.png\n",
      "Processed: 0000000090.png\n",
      "Processed: 0000000095.png\n",
      "Processed: 0000000100.png\n",
      "Processed: 0000000105.png\n",
      "Processed: 0000000110.png\n",
      "Processed: 0000000115.png\n",
      "Processed: 0000000120.png\n",
      "Processed: 0000000125.png\n",
      "Processed: 0000000130.png\n",
      "Processed: 0000000135.png\n",
      "Processed: 0000000140.png\n",
      "Processed: 0000000145.png\n",
      "Processed: 0000000150.png\n",
      "Processed: 0000000155.png\n",
      "Processed: 0000000160.png\n",
      "Processed: 0000000165.png\n",
      "Processed: 0000000170.png\n",
      "Processed: 0000000175.png\n",
      "Processed: 0000000180.png\n",
      "Processed: 0000000185.png\n",
      "Processed: 0000000190.png\n",
      "Processed: 0000000195.png\n",
      "Processed: 0000000200.png\n",
      "AU detection complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting frames...\")\n",
    "frames_df = get_frames_from_video_opencv(video_path, temp_dir=temp_dir)\n",
    "frames_df = frames_df.iloc[::5]\n",
    "\n",
    "if frames_df.empty:\n",
    "    print(\"No frames extracted.\")\n",
    "    exit()\n",
    "\n",
    "def draw_aus_on_frame(frame, aus: dict):\n",
    "    y0, dy = 30, 30\n",
    "    for i, (au, intensity) in enumerate(aus.items()):\n",
    "        y = y0 + i * dy\n",
    "        label = f\"{au}: {intensity}\"\n",
    "        cv2.putText(frame, label, (10, y), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    1.2 , (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    return frame\n",
    "\n",
    "# === AU detection ===\n",
    "for _, row in frames_df.iterrows():\n",
    "    frame_path = row['path_to_frame']\n",
    "    frame = cv2.imread(frame_path)\n",
    "\n",
    "    if frame is None:\n",
    "        print(f\"Could not read: {frame_path}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        detected_aus, au_intensities = get_au_intensities_and_detect_aus(\n",
    "            image_path=frame_path,\n",
    "            device=device,\n",
    "            weights_download_dir=weights_dir\n",
    "        )\n",
    "        annotated_data = {au: f\"{au_intensities[au]:.2f}\" for au in au_intensities}\n",
    "\n",
    "        annotated_frame = draw_aus_on_frame(frame.copy(), annotated_data)\n",
    "\n",
    "        frame_filename = os.path.basename(frame_path)\n",
    "        out_path = os.path.join(output_dir, frame_filename)\n",
    "        cv2.imwrite(out_path, annotated_frame)\n",
    "\n",
    "        print(f\"Processed: {frame_filename}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed: {frame_path} â€“ {e}\")\n",
    "\n",
    "print(\"AU detection complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a91529",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
